{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import io\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import (\n",
    "    EfficientNetB0, MobileNetV2, ResNet50, InceptionV3\n",
    ")\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_pre\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mob_pre\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as res_pre\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inc_pre\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile, os\n",
    "\n",
    "uploaded = files.upload()\n",
    "zip_name = list(uploaded.keys())[0]\n",
    "\n",
    "with zipfile.ZipFile(zip_name, 'r') as z:\n",
    "    z.extractall('/content/data')\n",
    "\n",
    "!find /content/data -maxdepth 3 -type d -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = '/content/data' #@param {type:\"string\"}\n",
    "USE_LABELS_CSV = False #@param {type:\"boolean\"}\n",
    "LABELS_CSV_PATH = '/content/data/my_dataset/labels.csv' #@param {type:\"string\"}\n",
    "\n",
    "BACKBONE = 'MobileNetV2' #@param [\"EfficientNetB0\", \"MobileNetV2\", \"ResNet50\", \"InceptionV3\"]\n",
    "\n",
    "# Train parameters\n",
    "IMG_SIZE = 224 #@param {type:\"integer\"}\n",
    "BATCH_SIZE = 32 #@param {type:\"integer\"}\n",
    "EPOCHS = 15 #@param {type:\"integer\"}\n",
    "VAL_SPLIT = 0.2 #@param {type:\"number\"}\n",
    "AUTO_SPLIT_IF_NO_VAL = True #@param {type:\"boolean\"}\n",
    "AUGMENTATION = False #@param {type:\"boolean\"}\n",
    "LEARNING_RATE = 0.0005 #@param {type:\"number\"}\n",
    "\n",
    "OUTPUT_DIR = '/content/output' #@param {type:\"string\"}\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print('Ayarlar yüklendi.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(DATA_DIR, 'train')\n",
    "val_dir = os.path.join(DATA_DIR, 'val')\n",
    "\n",
    "if os.path.isdir(train_dir) and (not os.path.isdir(val_dir)) and AUTO_SPLIT_IF_NO_VAL and not USE_LABELS_CSV:\n",
    "    tmp_out = '/content/data_split'\n",
    "    if os.path.exists(tmp_out):\n",
    "        shutil.rmtree(tmp_out)\n",
    "    splitfolders.ratio(train_dir, output=tmp_out, seed=42, ratio=(1-VAL_SPLIT, VAL_SPLIT))\n",
    "    DATA_DIR = tmp_out\n",
    "    train_dir = os.path.join(DATA_DIR, 'train')\n",
    "    val_dir = os.path.join(DATA_DIR, 'val')\n",
    "\n",
    "print('train_dir:', train_dir)\n",
    "print('val_dir  :', val_dir)\n",
    "\n",
    "IMG_SIZE = int(IMG_SIZE)\n",
    "img_size = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "if not USE_LABELS_CSV:\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train_dir, image_size=img_size, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        val_dir, image_size=img_size, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "    with open(\"class_names.txt\", \"w\") as f:\n",
    "        for cls in class_names:\n",
    "            f.write(cls + \"\\n\")\n",
    "    print(\"✅ class_names.txt created, content:\", class_names)\n",
    "else:\n",
    "\n",
    "    df = pd.read_csv(LABELS_CSV_PATH)\n",
    "    class_names = sorted(df['label'].unique().tolist())\n",
    "    class_to_idx = {c:i for i,c in enumerate(class_names)}\n",
    "\n",
    "    paths = df['filepath'].tolist()\n",
    "    labels = df['label'].map(class_to_idx).values\n",
    "\n",
    "    def load_image(path, label):\n",
    "        raw = tf.io.read_file(os.path.join(DATA_DIR, path))\n",
    "        img = tf.io.decode_image(raw, channels=3)\n",
    "        img = tf.image.resize(img, img_size)\n",
    "        img.set_shape((IMG_SIZE, IMG_SIZE, 3))\n",
    "        return img, label\n",
    "\n",
    "    full_ds = tf.data.Dataset.from_tensor_slices((paths, labels)).map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    n_total = len(paths)\n",
    "    n_val = int(n_total * VAL_SPLIT)\n",
    "    val_ds = full_ds.take(n_val).batch(BATCH_SIZE)\n",
    "    train_ds = full_ds.skip(n_val).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print('Sınıflar:', class_names)\n",
    "NUM_CLASSES = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = widgets.Button(\n",
    "    description=\"Download class_names.txt\",\n",
    "    button_style=\"success\",\n",
    "    icon=\"download\",\n",
    "    layout=widgets.Layout(width=\"auto\")\n",
    ")\n",
    "\n",
    "def _on_click(b):\n",
    "    files.download(\"class_names.txt\")\n",
    "\n",
    "btn.on_click(_on_click)\n",
    "display(btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tmp = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=32, shuffle=False\n",
    ")\n",
    "correct_names = ds_tmp.class_names  # alfabetik klasör sırası\n",
    "print(\"Correct class order:\", correct_names)\n",
    "\n",
    "with open(\"class_names.txt\", \"w\") as f:\n",
    "    for cls in correct_names:\n",
    "        f.write(cls + \"\\n\")\n",
    "print(\"✅ Rebuilt class_names.txt\")\n",
    "\n",
    "# (İstersen indir)\n",
    "from google.colab import files\n",
    "files.download(\"class_names.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess_map = {\n",
    "    'EfficientNetB0': eff_pre,\n",
    "    'MobileNetV2': mob_pre,\n",
    "    'ResNet50': res_pre,\n",
    "    'InceptionV3': inc_pre\n",
    "}\n",
    "\n",
    "base_map = {\n",
    "    'EfficientNetB0': EfficientNetB0,\n",
    "    'MobileNetV2': MobileNetV2,\n",
    "    'ResNet50': ResNet50,\n",
    "    'InceptionV3': InceptionV3\n",
    "}\n",
    "\n",
    "pre_fn = preprocess_map[BACKBONE]\n",
    "BaseClass = base_map[BACKBONE]\n",
    "\n",
    "\n",
    "if AUGMENTATION:\n",
    "    aug = tf.keras.Sequential([\n",
    "        layers.RandomFlip('horizontal'),\n",
    "        layers.RandomRotation(0.05),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ], name=\"aug\")\n",
    "else:\n",
    "\n",
    "    aug = layers.Lambda(lambda x: x, name=\"identity_aug\")\n",
    "\n",
    "\n",
    "pre = tf.keras.layers.Lambda(pre_fn)\n",
    "\n",
    "base = BaseClass(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights='imagenet')\n",
    "base.trainable = False\n",
    "inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = aug(inp)\n",
    "x = pre(x)\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "out = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inp, out)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ckpt_path = os.path.join(OUTPUT_DIR, f'{BACKBONE}_best.keras')\n",
    "callbacks = [\n",
    "    ModelCheckpoint(ckpt_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
    "]\n",
    "\n",
    "hist = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n",
    "\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE/10),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist_ft = model.fit(train_ds, validation_data=val_ds, epochs=max(3, EPOCHS//3), callbacks=callbacks)\n",
    "\n",
    "print('EBest model:', ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_history(h1, h2):\n",
    "    history = {}\n",
    "    for key in h1.history.keys():\n",
    "        history[key] = h1.history[key] + h2.history[key]\n",
    "    return history\n",
    "\n",
    "history = combine_history(hist, hist_ft)\n",
    "\n",
    "# Plot training vs validation accuracy and loss\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for imgs, labels in val_ds:\n",
    "    preds = model.predict(imgs, verbose=0)\n",
    "    y_true.extend(labels.numpy().tolist())\n",
    "    y_pred.extend(np.argmax(preds, axis=1).tolist())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(NUM_CLASSES)\n",
    "plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, os\n",
    "\n",
    "# Keras\n",
    "keras_path = os.path.join(OUTPUT_DIR, f'{BACKBONE}_final.keras')\n",
    "model.save(keras_path)\n",
    "\n",
    "# SavedModel\n",
    "sm_path = os.path.join(OUTPUT_DIR, f'{BACKBONE}_savedmodel')\n",
    "model.export(sm_path)\n",
    "\n",
    "# TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(sm_path)\n",
    "tflite_model = converter.convert()\n",
    "with open(os.path.join(OUTPUT_DIR, f'{BACKBONE}.tflite'), 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print('Kayıt klasörü:', OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zip_dir(src_dir, zip_path):\n",
    "    # Remove existing zip if present\n",
    "    if os.path.exists(zip_path):\n",
    "        os.remove(zip_path)\n",
    "    base, _ = os.path.splitext(zip_path)\n",
    "    # shutil.make_archive wants base name without .zip + format\n",
    "    shutil.make_archive(base, 'zip', root_dir=src_dir)\n",
    "    return zip_path\n",
    "\n",
    "def _safe_download(path):\n",
    "    if os.path.exists(path):\n",
    "        files.download(path)\n",
    "        print(f\"Downloading: {os.path.basename(path)}\")\n",
    "    else:\n",
    "        print(f\"Not found: {path}\")\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "btn_keras = widgets.Button(\n",
    "    description=\"Download .keras\",\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width=\"500px\", height=\"100px\")\n",
    ")\n",
    "\n",
    "btn_tflite = widgets.Button(\n",
    "    description=\"Download .tflite\",\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width=\"500px\", height=\"100px\")\n",
    ")\n",
    "\n",
    "btn_savedmodel = widgets.Button(\n",
    "    description=\"Download SavedModel (.zip)\",\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width=\"500px\", height=\"100px\")\n",
    ")\n",
    "\n",
    "btn_all = widgets.Button(\n",
    "    description=\"Download ALL outputs (.zip)\",\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width=\"500px\", height=\"60px\")\n",
    ")\n",
    "\n",
    "widgets.HBox([btn_keras, btn_tflite, btn_savedmodel, btn_all])\n",
    "\n",
    "\n",
    "# --- Paths (re-derive defensively in case the user runs this cell alone) ---\n",
    "keras_path = os.path.join(OUTPUT_DIR, f\"{BACKBONE}_final.keras\")\n",
    "tflite_path = os.path.join(OUTPUT_DIR, f\"{BACKBONE}.tflite\")\n",
    "sm_dir     = os.path.join(OUTPUT_DIR, f\"{BACKBONE}_savedmodel\")\n",
    "\n",
    "savedmodel_zip = os.path.join(OUTPUT_DIR, f\"{BACKBONE}_savedmodel.zip\")\n",
    "all_outputs_zip = os.path.join(OUTPUT_DIR, f\"{BACKBONE}_all_outputs.zip\")\n",
    "\n",
    "# --- Buttons ---\n",
    "btn_keras = widgets.Button(description=\"Download .keras\", button_style='primary')\n",
    "btn_tflite = widgets.Button(description=\"Download .tflite\", button_style='primary')\n",
    "btn_savedmodel = widgets.Button(description=\"Download SavedModel (.zip)\", button_style='primary')\n",
    "btn_all = widgets.Button(description=\"Download ALL outputs (.zip)\", button_style='primary')\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "# --- Callbacks ---\n",
    "def on_click_keras(b):\n",
    "    with out:\n",
    "        _safe_download(keras_path)\n",
    "\n",
    "def on_click_tflite(b):\n",
    "    with out:\n",
    "        _safe_download(tflite_path)\n",
    "\n",
    "def on_click_savedmodel(b):\n",
    "    with out:\n",
    "        if os.path.isdir(sm_dir):\n",
    "            print(\"Zipping SavedModel directory...\")\n",
    "            _zip_dir(sm_dir, savedmodel_zip)\n",
    "            _safe_download(savedmodel_zip)\n",
    "        else:\n",
    "            print(f\"SavedModel directory not found: {sm_dir}\")\n",
    "\n",
    "def on_click_all(b):\n",
    "    with out:\n",
    "        if os.path.isdir(OUTPUT_DIR):\n",
    "            print(\"Zipping all outputs...\")\n",
    "            _zip_dir(OUTPUT_DIR, all_outputs_zip)\n",
    "            _safe_download(all_outputs_zip)\n",
    "        else:\n",
    "            print(f\"Output folder not found: {OUTPUT_DIR}\")\n",
    "\n",
    "btn_keras.on_click(on_click_keras)\n",
    "btn_tflite.on_click(on_click_tflite)\n",
    "btn_savedmodel.on_click(on_click_savedmodel)\n",
    "btn_all.on_click(on_click_all)\n",
    "\n",
    "# --- UI layout ---\n",
    "box = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>Download trained model files</h4>\"\n",
    "                 \"<p>Click a button to download. If a file or folder is missing, run the training cells first.</p>\"),\n",
    "    widgets.HBox([btn_keras, btn_tflite]),\n",
    "    widgets.HBox([btn_savedmodel, btn_all]),\n",
    "    out\n",
    "])\n",
    "\n",
    "display(box)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

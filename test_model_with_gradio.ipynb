{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install \"tensorflow==2.19.0\" \"tf-keras==2.19.0\" \"keras==3.5.0\" \"numpy==2.0.2\" \"Pillow>=10.3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, keras, numpy as np\n",
    "import os, io, zipfile, tempfile, json\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "print(\"TF\", tf.__version__, \"| Keras\", keras.__version__, \"| NumPy\", np.__version__)\n",
    "# Beklenen: TF 2.19.0 | Keras 3.5.x | NumPy 2.0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow unsafe deserialization (for trusted models with Lambda layers)\n",
    "try:\n",
    "    keras.config.enable_unsafe_deserialization()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Patch for DepthwiseConv2D with \"groups\" argument compatibility\n",
    "from tensorflow.keras.layers import DepthwiseConv2D as _TFDepthwiseConv2D\n",
    "class DepthwiseConv2DCompat(_TFDepthwiseConv2D):\n",
    "    def __init__(self, *args, groups=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "CUSTOM_OBJECTS_BASE = {\"DepthwiseConv2D\": DepthwiseConv2DCompat}\n",
    "\n",
    "# Candidate preprocess functions\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_pre\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mob_pre\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as res_pre\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inc_pre\n",
    "\n",
    "PREPROCESS_CANDIDATES = {\n",
    "    \"EfficientNetB0\": eff_pre,\n",
    "    \"MobileNetV2\":   mob_pre,\n",
    "    \"ResNet50\":      res_pre,\n",
    "    \"InceptionV3\":   inc_pre,\n",
    "}\n",
    "\n",
    "def _infer_input_size(model):\n",
    "    \"\"\"Infer input image size and channels from the model.\"\"\"\n",
    "    ishape = model.input_shape\n",
    "    if isinstance(ishape, list):\n",
    "        ishape = ishape[0]\n",
    "    _, h, w, c = ishape\n",
    "    if h is None or w is None:\n",
    "        h, w = 224, 224\n",
    "    return (w, h), c\n",
    "\n",
    "def _prep_image(pil_img, size, channels, preprocess=None, scale_255=True):\n",
    "    \"\"\"Prepare image for prediction, avoiding double-preprocessing.\"\"\"\n",
    "    img = pil_img.convert(\"RGB\").resize(size)\n",
    "    x = np.array(img, dtype=np.float32)\n",
    "    if channels == 1:\n",
    "        x = np.mean(x, axis=-1, keepdims=True)\n",
    "    if preprocess is not None:\n",
    "        x = preprocess(x)  # don't /255 here\n",
    "    else:\n",
    "        if scale_255:\n",
    "            x = x / 255.0\n",
    "        # else keep raw 0..255\n",
    "    return np.expand_dims(x, 0)\n",
    "\n",
    "def _try_load_no_custom(path_or_dir):\n",
    "    \"\"\"Try loading WITHOUT providing preprocess_input.\"\"\"\n",
    "    co = dict(CUSTOM_OBJECTS_BASE)\n",
    "    return tf.keras.models.load_model(\n",
    "        path_or_dir, compile=False, safe_mode=False, custom_objects=co\n",
    "    )\n",
    "\n",
    "def _read_class_names(txt_path: str):\n",
    "    \"\"\"Read class names from a text file (one class per line).\"\"\"\n",
    "    if not txt_path:\n",
    "        return None\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        names = [ln.strip() for ln in f if ln.strip()]\n",
    "    return names or None\n",
    "\n",
    "def _load_model_any(model_path: str, backbone_hint: str | None):\n",
    "    \"\"\"Load model and detect whether it contains internal preprocess_input Lambda.\"\"\"\n",
    "    def _resolve_zip(path):\n",
    "        workdir = tempfile.mkdtemp()\n",
    "        with zipfile.ZipFile(path, \"r\") as zf:\n",
    "            zf.extractall(workdir)\n",
    "        cand = None\n",
    "        for root, _, files in os.walk(workdir):\n",
    "            if \"saved_model.pb\" in files:\n",
    "                cand = root; break\n",
    "        if not cand:\n",
    "            raise RuntimeError(\"No SavedModel (saved_model.pb) found inside the zip.\")\n",
    "        return cand\n",
    "\n",
    "    low = model_path.lower()\n",
    "    target = _resolve_zip(model_path) if low.endswith(\".zip\") else model_path\n",
    "\n",
    "    # 1) Try WITHOUT preprocess_input (means no internal Lambda)\n",
    "    try:\n",
    "        m = _try_load_no_custom(target)\n",
    "        return m, None, None, False  # (model, used_backbone, used_pre_fn, has_internal_pre)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Fall back WITH candidates (selected backbone first)\n",
    "    order = []\n",
    "    if backbone_hint in PREPROCESS_CANDIDATES:\n",
    "        order.append((backbone_hint, PREPROCESS_CANDIDATES[backbone_hint]))\n",
    "    for name, fn in PREPROCESS_CANDIDATES.items():\n",
    "        if name != backbone_hint:\n",
    "            order.append((name, fn))\n",
    "\n",
    "    last_err = None\n",
    "    for name, fn in order:\n",
    "        try:\n",
    "            co = dict(CUSTOM_OBJECTS_BASE); co[\"preprocess_input\"] = fn\n",
    "            m = tf.keras.models.load_model(target, compile=False, safe_mode=False, custom_objects=co)\n",
    "            return m, name, fn, True   # internal Lambda present\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Model could not be deserialized. Last error: {last_err}\")\n",
    "\n",
    "# === Gradio UI ===\n",
    "with gr.Blocks(title=\"Keras Image Classifier\") as demo:\n",
    "    gr.Markdown(\"## Keras Image Classifier\\nUpload your model (.keras/.h5/.zip) and **class_names.txt**, pick the backbone if needed, then select an image to get predictions.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(\n",
    "            label=\"Model File (.keras / .h5 / SavedModel .zip)\",\n",
    "            file_types=[\".keras\", \".h5\", \".zip\"],\n",
    "            type=\"filepath\"\n",
    "        )\n",
    "        class_file = gr.File(\n",
    "            label=\"Class Names File (class_names.txt)\",\n",
    "            file_types=[\".txt\"],\n",
    "            type=\"filepath\"\n",
    "        )\n",
    "        backbone_dropdown = gr.Dropdown(\n",
    "            choices=[\"EfficientNetB0\", \"MobileNetV2\", \"ResNet50\", \"InceptionV3\"],\n",
    "            label=\"Backbone (used for deserialization if needed)\",\n",
    "            value=\"MobileNetV2\"\n",
    "        )\n",
    "\n",
    "    load_btn = gr.Button(\"Load Model\", variant=\"primary\")\n",
    "    status = gr.Markdown()\n",
    "\n",
    "    # States\n",
    "    model_state = gr.State()\n",
    "    input_size_state = gr.State()\n",
    "    channels_state = gr.State()\n",
    "    class_names_state = gr.State()\n",
    "    preprocess_fn_state = gr.State()\n",
    "    backbone_used_state = gr.State()\n",
    "    has_internal_pre_state = gr.State()  # <â€” moved here with the others\n",
    "\n",
    "    with gr.Row():\n",
    "        image_in = gr.Image(type=\"pil\", label=\"Input Image\")\n",
    "        predict_btn = gr.Button(\"Predict\", variant=\"primary\")\n",
    "\n",
    "    label_out = gr.Label(num_top_classes=5, label=\"Top-5 Predictions\")\n",
    "\n",
    "    def on_load(model_path, class_path, backbone_hint):\n",
    "        if not model_path:\n",
    "            return \"Please choose a model.\", None, None, None, None, None, None, None\n",
    "        try:\n",
    "            m, used_backbone, used_pre, has_internal = _load_model_any(model_path, backbone_hint)\n",
    "            (w, h), c = _infer_input_size(m)\n",
    "            classes = _read_class_names(class_path)\n",
    "            msg = f\"Model loaded. Input shape: {(h,w,c)}\"\n",
    "            if has_internal:\n",
    "                msg += \" | Preprocessing: inside model (no external scaling).\"\n",
    "            else:\n",
    "                msg += f\" | External preprocessing: {used_backbone or '/255'}\"\n",
    "            if classes:\n",
    "                msg += f\" | {len(classes)} classes loaded.\"\n",
    "            else:\n",
    "                msg += \" | No class_names.txt found, using class_0, class_1, ...\"\n",
    "            # If internal preprocess present, do NOT pass a preprocess fn; also do NOT /255\n",
    "            preprocess_for_runtime = None if has_internal else used_pre  # may be None -> then we will /255\n",
    "            return msg, m, (w, h), c, classes, preprocess_for_runtime, (used_backbone or \"/255\"), has_internal\n",
    "        except Exception as e:\n",
    "            return f\"Failed to load model: {e}\", None, None, None, None, None, None, None\n",
    "\n",
    "    load_btn.click(\n",
    "        on_load,\n",
    "        inputs=[model_file, class_file, backbone_dropdown],\n",
    "        outputs=[status, model_state, input_size_state, channels_state, class_names_state, preprocess_fn_state, backbone_used_state, has_internal_pre_state]\n",
    "    )\n",
    "\n",
    "    def on_predict(img, model, input_size, channels, class_names, preprocess_fn, backbone_used, has_internal_pre):\n",
    "        if model is None:\n",
    "            return {\"error\": 1.0}\n",
    "        if img is None:\n",
    "            return {\"no_image\": 1.0}\n",
    "        try:\n",
    "            x = _prep_image(\n",
    "                img, input_size, channels,\n",
    "                preprocess=(None if has_internal_pre else preprocess_fn),\n",
    "                scale_255=(False if has_internal_pre else (preprocess_fn is None))\n",
    "            )\n",
    "            y = model.predict(x, verbose=0)\n",
    "            y = y[0] if isinstance(y, (list, tuple)) else y\n",
    "            y = np.array(y).reshape(-1)\n",
    "\n",
    "            # Binary case\n",
    "            if y.shape == () or y.shape == (1,):\n",
    "                p = float(y if y.shape == () else y[0])\n",
    "                p = 1 / (1 + np.exp(-p)) if (p < 0 or p > 1) else p\n",
    "                return {\"positive\": p, \"negative\": 1.0 - p}\n",
    "\n",
    "            # Multiclass case\n",
    "            if class_names and len(class_names) == y.shape[-1]:\n",
    "                return {cls: float(p) for cls, p in zip(class_names, y)}\n",
    "            return {f\"class_{i}\": float(p) for i, p in enumerate(y)}\n",
    "        except Exception as e:\n",
    "            return {f\"error: {e}\": 1.0}\n",
    "\n",
    "    predict_btn.click(\n",
    "        on_predict,\n",
    "        inputs=[image_in, model_state, input_size_state, channels_state, class_names_state, preprocess_fn_state, backbone_used_state, has_internal_pre_state],\n",
    "        outputs=[label_out]\n",
    "    )\n",
    "\n",
    "demo.queue().launch()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
